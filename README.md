# ğŸ“¸ğŸ§  StoryTellerAI: An approach to Visual Storytelling

Turn a series of images into a narrated short story using state-of-the-art AI models!  
This project combines image captioning, object detection, LLM-based storytelling, and TTS voice narration.

---

## ğŸ¯ What It Does

1. ğŸ–¼ï¸ **Capture or Load Images**  
2. ğŸ§  **Generate Smart Captions** using [BLIP-2](https://huggingface.co/Salesforce/blip2-opt-2.7b)  
3. ğŸ” **Detect Objects** with [YOLOv11](https://github.com/ultralytics/ultralytics)  
4. ğŸ“– **Write a Genre-Specific Story** with [LLaMA 3](https://ai.meta.com/llama/)  
5. ğŸ”Š **Narrate the Story** using a cloned voice with [F5-TTS](https://github.com/TensorSpeech/FastSpeech2)  
6. ğŸ¬ **Display it with Subtitles and Audio** â€” like a slideshow movie!

---

## ğŸ§° Requirements

- Python 3.9+
- GPU (recommended)
- Pre-trained models:
  - `Salesforce/blip2-opt-2.7b`
  - `YOLOv11` variant (`yolo11x.pt`)
  - `Llama-3.2-3B-Instruct-F16.gguf`
  - `F5-TTS` with cloned voice checkpoint

---

## ğŸ—‚ Folder Structure

```
â”œâ”€â”€ images/               # Input image frames (if not using webcam)
â”œâ”€â”€ models/               # All models stored here
â”‚   â”œâ”€â”€ blip2_model/
â”‚   â”œâ”€â”€ blip2_processor/
â”‚   â”œâ”€â”€ Llama-3.2-3B-Instruct-F16.gguf
â”‚   â””â”€â”€ yolo11x.pt
â”œâ”€â”€ audio/
â”‚   â”œâ”€â”€  reference_audio.wav     # 10-20s voice sample
    â”œâ”€â”€  reference_text.txt      # Transcribed reference_audio.wav
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ outputX.wav             # Output narrated files
â”œâ”€â”€ PMBA_code.py                    # Run this file!
â””â”€â”€ README.md
```

---

## ğŸš€ Getting Started

```bash
# Clone the repo and navigate into the directory
git clone https://github.com/PedroFerreira03/StoryTellerAI
cd StoryTellerAI

# Run and take new photos using your webcam
python PMBA_code.py --photo

# Or run with existing images from the /images folder
python PMBA_code.py
```

ğŸ“Œ At the end, press any key to view the narrated story frame-by-frame.

## ğŸ® Choose Your Genre
You'll be prompted to select the story's theme:

What genre do you wish the story to be in?
Examples:

ğŸ§™ Fantasy

ğŸ‘½ Sci-Fi

ğŸ•µï¸ Mystery

ğŸ­ Drama

ğŸ‰ Comedy

ğŸ¦¸ Superhero

...or make up your own!

This genre is passed as context to the LLM.

## ğŸ§ª Voice Cloning (Optional)
Record a 20-second voice sample and save it as:
audio/reference_audio.wav

Edit the main.py to include a reference text that matches your voice (helps TTS align better).

Install and configure F5-TTS or your preferred voice model.

Make sure the CLI tool is available:
f5-tts_infer-cli --text "Your story here" --ref audio/reference_audio.wav

## ğŸ“½ï¸ Output
Once the story and narration are generated, the program displays a slideshow:

Each image appears

Subtitles are shown

Audio is played frame-by-frame

You can save the audio (outputX.wav) from /tests/.

## ğŸ§  Powered By
BLIP-2 â€“ Vision-Language model for captions

YOLOv11 â€“ Object detection

LLaMA 3 â€“ Story generation LLM

F5-TTS â€“ Voice synthesis
